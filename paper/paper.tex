\documentclass[runningheads]{llncs}
\usepackage{graphicx}
%\usepackage[UKenglish]{babel}
%\usepackage[UKenglish]{isodate}
%\usepackage[utf8]{inputenc}
\usepackage[ruled,vlined]{algorithm2e}
\usepackage{amssymb}
\usepackage{mathtools}
\usepackage[capitalise]{cleveref}
\usepackage{tikz}
\usepackage{mathrsfs}

\usetikzlibrary{arrows.meta}

\newtheorem{constraint}{Constraint}

\newcommand{\variable}[1]{\texttt{\textup{#1}}}
\newcommand{\arrayd}[3]{\variable{{#1}[}{#2}\variable{]} \in {#3}}
\newcommand{\arrayt}[3]{\variable{{#3}[}{#2}\variable{] {#1}}}
\newcommand{\predicates}{\mathcal{P}}
\newcommand{\variables}{\mathcal{V}}
\newcommand{\constants}{\mathcal{C}}
\newcommand{\tokens}{\mathcal{T}}
\newcommand{\arities}{\mathcal{A}}
\newcommand{\maxArity}{\mathcal{M}_{\mathcal{A}}}
\newcommand{\maxNumNodes}{\mathcal{M}_{\mathcal{N}}}
\newcommand{\maxNumClauses}{\mathcal{M}_{\mathcal{C}}}

%\relpenalty=10000
%\binoppenalty=10000
\def\multiset#1#2{\ensuremath{\left(\kern-.3em\left(\genfrac{}{}{0pt}{}{#1}{#2}\right)\kern-.3em\right)}}

\begin{document}

\title{Generating Random Logic Programs Using Constraint Programming}
\author{Paulius Dilkas\orcidID{0000-1111-2222-3333}}
\authorrunning{P. Dilkas}
% First names are abbreviated in the running head.
% If there are more than two authors, 'et al.' is used.

\institute{University of Edinburgh, Edinburgh, United Kingdom\\
  \email{p.dilkas@sms.ed.ac.uk}}
\maketitle

\begin{abstract}
The abstract should briefly summarize the contents of the paper in
150--250 words.

\keywords{Constraint Programming \and Logic Programming \and Probabilistic Logic
  Programming.}
\end{abstract}

\section{Introduction}

Motivation:
\begin{itemize}
\item Generating random programs that generate random data.
  %For example, enforcing that the decision is independent of gender.
\item Learning: how this can be used for (targeted) learning, when (atomic)
  probabilities can be assigned based on counting and we can have extra
  constraints. A more primitive angle: generate structures, learn weights.
\end{itemize}

TODO: define all the relevant terminology from logic. If a predicate has arity
$n$ and it is as of yet undecided what $n$ terms will fill those spots, we will
say that the predicate has $n$ \emph{gaps}.

We will often use $\Box$ as a special domain value indicating a `disabled'
(i.e., fixed and ignored) part of the model. We write $\arrayd{a}{b}{c}$ to mean
that $\variable{a}$ is an array of variables of length $b$ such that each
element of $\variable{a}$ has domain $c$. Similarly, we write $\arrayt{a}{b}{c}$
to denote an array $\variable{a}$ of length $b$ such that each element of
$\variable{a}$ has type $\variable{c}$. All constraint variables in the model
are integer variables, but, e.g., if the integer $i$ refers to a logical
variable $X$, we will use $i$ and $X$ interchangeably. All indices start at
zero.

We also use Choco~4.10.2 \cite{choco}. This works with both Prolog
\cite{DBLP:books/daglib/0041598} and ProbLog \cite{DBLP:conf/ijcai/RaedtKT07}.
Tested with SWI-Prolog \cite{DBLP:journals/tplp/WielemakerSTL12}.

\subsection{Parameters}

Parameters:
\begin{itemize}
\item a list of predicates $\predicates{}$,
\item a list of their arities $\arities{}$ (including zero),
  \begin{itemize}
  \item maximum arity $\maxArity{} \coloneqq \max \arities{}$.
  \end{itemize}
\item a list of variables $\variables{}$,
\item and a list of constants $\constants{}$.
  \begin{itemize}
  \item Each of them can be empty, but $|\constants{}| + |\variables{}| > 0$.
  \end{itemize}
\item a list of probabilities that are randomly assigned to clauses,
\item option to forbid all cycles or just negative cycles,
\item $\maxNumNodes{} \ge 1$: maximum number of nodes in the tree representation
  of a clause,
\item $\maxNumClauses{} \ge |\predicates{}|$: maximum number of clauses in a
  program,
\item maximum number of solutions,
\end{itemize}

We also define $\tokens{} = \{ \neg, \land, \lor, \top \}$. All decision
variables of the model are contained in two arrays:
\begin{itemize}
\item $\arrayt{bodiesOfClauses}{\maxNumClauses{}}{Body}$,
\item $\arrayt{headsOfClauses}{\maxNumClauses{}}{Head}$
\end{itemize}

\section{Heads of Clauses}

\begin{definition}
  The \emph{head} of a clause is composed of:
  \begin{itemize}
  \item a $\variable{predicate} \in \predicates \cup \{ \Box \}$.
  \item and $\arrayd{arguments}{\maxArity{}}{\constants{} \cup \variables{}}
    \cup \{ \Box \}$
  \end{itemize}
\end{definition}
The reason why $\Box$ must be a separate value will become clear in
\cref{sec:variable_symmetry}.

\begin{definition} \label{def:arity}
  The \variable{predicate}'s $\variable{arity} \in [0, \maxArity{}]$ can then be
  defined using the \variable{table} constraint as
  \[
    \variable{arity} = \begin{cases}
      \text{the arity of } \variable{predicate} & \text{if }
      \variable{predicate} \in \predicates{}\\
      0 & \text{otherwise.}
    \end{cases}
  \]
\end{definition}

\begin{constraint} \label{constr:arity}
  For $i = 0, \dots, \maxArity{} - 1$,
  \[
    \variable{arguments}[i] = \Box \iff i \ge \variable{arity}.
  \]
\end{constraint}

\section{Bodies of Clauses}

\begin{definition}
  The body of a clause is defined by:
  \begin{itemize}
  \item $\arrayd{treeStructure}{\maxNumNodes{}}{[0, \maxNumNodes{} - 1]}$ such
    that:
    \begin{itemize}
    \item $\variable{treeStructure}[i] = i$: the $i$-th node is a root.
    \item $\variable{treeStructure}[i] = j$: the $i$-th node's parent is node $j$.
    \end{itemize}
  \item $\arrayt{treeValues}{\maxNumNodes{}}{Node}$.
  \end{itemize}
\end{definition}

\begin{figure}[t]
  \centering
  \begin{tikzpicture}
    \node[draw,circle,gray,text=black] (or) at (0, 0) {$\lor$};
    \node[draw,circle,gray,text=black] (not) at (-1, -1) {$\neg$};
    \node (P) at (-1, -2) {$\mathsf{P}(X)$};
    \node[draw,circle,gray,text=black] (and) at (1, -1) {$\land$};
    \node (Q) at (0, -2) {$\mathsf{Q}(X)$};
    \node (R) at (2, -2) {$\mathsf{P}(X)$};
    \draw[gray] (or) -- (not);
    \draw[gray] (or) -- (and);
    \draw[gray] (not) -- (P);
    \draw[gray] (and) -- (Q);
    \draw[gray] (and) -- (R);
  \end{tikzpicture}
  \caption{A tree representation of the formula from \cref{example:formula}}
  \label{fig:example_tree}
\end{figure}

\begin{example} \label{example:formula}
  Let $\maxNumNodes{} = 8$. Then $\neg\mathsf{P}(X) \lor (\mathsf{Q}(X)
  \land \mathsf{P}(X))$ corresponds to the tree in \cref{fig:example_tree} and
  can be encoded as:
  \begin{alignat*}{8}
    \variable{treeStructure} &= [0, &&0, &&0, &&1, &&2, &&2, &&6, &&7],\\
    \variable{treeValues} &= [{\lor}, &&{\neg}, &&{\land}, \mathsf{P}(&&X), \mathsf{Q}(&&X), \mathsf{P}(&&X), &&\top, &&\top],\\
    \variable{numNodes} &= 6, && && && && && && &&\\
    \variable{numTrees} &= 3. && && && && && && &&
  \end{alignat*}
  In the rest of this section, we will describe how the elements of
  $\variable{treeValues}$ are encoded and list a series of constraints that make
  this representation unique.
\end{example}

\subsection{Nodes}

\begin{definition} \label{def:node}
  A \emph{node} has a $\variable{name} \in \tokens{} \cup \predicates{}$ and
  $\arrayd{arguments}{\maxArity{}}{\variables{} \cup \constants{} \cup \{ \Box
    \}}$. The node's $\variable{arity}$ can then be
  defined analogously to \cref{def:arity}.
\end{definition}

We can use \cref{constr:arity} again to disable extra arguments.

\begin{example}
  Let $\maxArity{} = 2$, $\predicates{} = [\mathsf{P}, \dots]$, $\arities{}
  = [1, \dots]$, and $X \in \variables{}$. Then the node representing atom
  $\mathsf{P}(X)$ has:
  \begin{align*}
    \variable{name} &= \mathsf{P},\\
    \variable{arguments} &= [X, \Box],\\
    \variable{arity} &= 1.
  \end{align*}
\end{example}

\subsection{Constraints}

\begin{definition}
  We define $\variable{numTrees} \in \{ 1, \dots, \maxNumNodes{} \}$ to count
  the number of trees in our representation of a clause using the
  $\variable{tree}(\variable{treeStructure}, \variable{numTrees})$\footnote{This
    constraint uses dominator-based filtering by Fages and Lorca
    \cite{DBLP:conf/cp/FagesL11}.} constraint.
\end{definition}

\begin{definition}
  For convenience, we also define $\variable{numNodes} \in \{ 1, \dots,
  \maxNumNodes{} \}$ to count the number of nodes in the main tree. We define it
  as
  \[
    \variable{numNodes} = \maxNumNodes{} - \variable{numTrees} + 1.
  \]
\end{definition}

\begin{constraint}
  $\variable{treeStructure}[0] = 0$.
\end{constraint}

\begin{constraint}
  \variable{treeStructure} is sorted.
\end{constraint}

\begin{constraint}
  For $i = 0, \dots, \maxNumNodes{} - 1$, if $\variable{numNodes} \le
  i$, then
  \[
    \variable{treeStructure}[i] = i \quad \text{and} \quad
    \variable{treeValues}[i].\variable{name} = \top,
  \]
  else
  \[
    \variable{treeStructure}[i] < \variable{numNodes}.
  \]
\end{constraint}

\begin{constraint}
  For $i = 0, \dots, \maxNumNodes{} - 1$,
  \begin{align*}
    \variable{count}(i, \variable{treeStructure}_{-i}) = 0 &\iff \variable{treeValues}[i].\variable{name} \in \predicates{} \cup \{ \top \},\\
    \variable{count}(i, \variable{treeStructure}_{-i}) = 1 &\iff \variable{treeValues}[i].\variable{name} = \neg,\\
    \variable{count}(i, \variable{treeStructure}_{-i}) > 1 &\iff \variable{treeValues}[i].\variable{name} \in \{ \land, \lor \},
  \end{align*}
  where $\variable{treeStructure}_{-i}$ denotes array $\variable{treeStructure}$
  with position $i$ skipped.
\end{constraint}
Each constraint corresponds to node $i$ having no children, one child, and
multiple children, respectively.


\begin{constraint}
  For $i = 0, \dots, \maxNumNodes{} - 1$,
  \[
    \variable{treeStructure}[i] \ne i \implies
    \variable{treeValues}[i].\variable{name} \ne \top.
  \]
\end{constraint}

\begin{constraint}
  For $i = 0, \dots, \maxNumClauses{} - 1$, if
  $\variable{headsOfClauses}[i].\variable{predicate} = \Box$, then
  \[
    \variable{bodiesOfClauses}[i].\variable{numNodes} = 1,
  \]
  and
  \[
    \variable{bodiesOfClauses}[i].\variable{treeValues}[0].\variable{name} =
    \top.
  \]
\end{constraint}

\section{Eliminating Variable Symmetries} \label{sec:variable_symmetry}

Given any clause, we can permute the variables in it without changing the
meaning of the clause or the entire program. Thus, we want to fix the order of
variables to eliminate unnecessary symmetries. Informally, we can say that
variable $X$ goes before variable $Y$ if its first occurrence in either the head
or the body of the clause is before the first occurrence of $Y$.

\begin{definition}
  Let $N = \maxArity{} \times (\maxNumNodes{} + 1)$. Let
  $\variable{terms}[N] \in \constants{} \cup \variables{} \cup \{ \Box
  \}$ be a flattened array of all gaps in a particular clause.

  Then we can use the $\variable{setsIntsChanneling}$ constraint
  to define $\variable{occurrences}[|\constants{}| + |\variables{}| + 1]$ as an
  array of subsets of $\{ 0, \dots, N-1 \}$ such that for all $i = 0, \dots, N
  - 1$, and $t \in \constants{} \cup \variables{} \cup \{ \Box \}$,
  \[
    i \in \variable{occurrences}[t] \quad \iff \quad
    \variable{terms}[i] = t
  \]
\end{definition}

\begin{definition}
  We define $\arrayd{introductions}{|\variables{}|}{\{ 0, \dots, N \}}$ such
  that for $v \in \variables{}$,
  \[
    \variable{introductions}[v] = \begin{cases}
      \min \variable{occurrences}[v] & \text{if }
      \variable{occurrences}[v] \ne \emptyset\\
      N & \text{otherwise.}
    \end{cases}
  \]
\end{definition}

\begin{constraint}
  $\variable{introductions}$ are sorted.
\end{constraint}

\begin{example}
  Let $\constants{} = \emptyset$, $\variables{} = \{ X, Y, Z \}$, $\maxArity{} =
  2$, $\maxNumNodes{} = 3$, and consider the clause
  \[
    \mathsf{sibling}(X, Y) \gets \mathsf{parent}(X, Z) \land
    \mathsf{parent}(Y, Z).
  \]
  Then $\variable{terms} = [X, Y, \Box, \Box, X, Z, Y, Z]$ (the boxes represent
  the conjunction node), $\variable{occurrences} = [\{ 0, 4 \}, \{ 1, 6 \},
  \{ 5, 7 \}, \{ 2, 3 \}]$, and $\variable{introductions} = [0, 1, 5]$.
\end{example}

\section{Interactions Between Clauses}

\begin{constraint}
  Each predicate gets at least one clause. Let
  \[
    P = \{ h.\variable{predicate} \mid h \in \variable{headsOfClauses} \}.
  \]
  Then
  \[
    \variable{nValues}(P) =
    \begin{cases}
      \variable{numPredicates} + 1 & \text{if } \variable{count}(\Box, P) > 0 \\
      \variable{numPredicates} & \text{otherwise.}
    \end{cases}
  \]
  Here, $\variable{nValues}(P)$ counts the number of unique values in $P$.
\end{constraint}

\begin{constraint}
  Clauses are sorted.
\end{constraint}

\section{Counting Programs}

In order to demonstrate the correctness of the model and explain it in more
detail, in this section we are going to derive combinatorial expressions for
counting the number of programs with up to $\maxNumClauses{}$ clauses and up to
$\maxNumNodes{}$ nodes per clause, and arbitrary $\predicates{}$,
$\arities{}$, $\variables{}$, and $\constants{}$. To simplify the task, we only
consider clauses without probabilities and disable (negative) cycle elimination.
It was experimentally confirmed that the model agrees with the combinatorial
formula from this section in 985 different scenarios. The \emph{total arity} of
a body of a clause is the sum total of arities of all predicates in the body.

We will first consider clauses with gaps, i.e., without taking variables and
constants into account. Let $T(n, a)$ denote the number of possible clause
bodies with $n$ nodes and total arity $a$. Then $T(1, a)$ is the number of
predicates in $\predicates{}$ with arity $a$, and the following recursive
definition can be applied for $n > 1$:
\[
  T(n, a) = T(n-1, a) + 2\sum_{\substack{c_1 + \dots + c_k = n - 1,\\
      2 \le k \le \frac{a}{\min \arities{}},\\
      c_i \ge 1 \text{ for all } i}} \sum_{\substack{d_1 + \dots + d_k = a,\\
    d_i \ge \min \arities{} \text{ for all } i}} \prod_{i=1}^k T(c_i, d_i).
\]
The first term here represents negation, i.e., negating an expression consumes
one node but otherwise leaves the task unchanged. If the first operation is not
negation, then it must be either conjunction or disjunction (hence the
coefficient `2'). In the first sum, $k$ represents the number of children of the
root node, and each $c_i$ is the number of nodes dedicated to child $i$. Thus,
the first sum iterates over all possible ways to partition the remaining $n-1$
nodes. Similarly, the second sum considers every possible way to partition the
total arity $a$ across the $k$ children nodes.

We can then count the number of possible clause bodies with total arity $a$ (and
any number of nodes) as
\[
  C(a) = \begin{cases}
    1 & \text{if } a = 0\\
    \sum_{n=1}^{\maxNumNodes{}} T(n, a) & \text{otherwise.}
  \end{cases}
\]
Here, the empty clause is considered separately.

The number of ways to fill $n$ gaps with terms can be expressed as
\[
  P(n) = |\constants{}|^n + \sum_{\substack{1 \le k \le |\variables{}|, \\ 0 =
      s_0 < s_1 < \dots < s_k < s_{k+1} = n+1}} \prod_{i=0}^k (|\constants{}| +
  i)^{s_{i+1} - s_i - 1}.
\]
The first term is simply the number of ways to fill all $n$ gaps with
constants. The parameter $k$ is the number of variables used in the clause, and
$s_1, \dots, s_k$ mark the first occurrence of each variable. For each gap
between any two introductions (or before the first introduction, or after the last
introduction), we have $s_{i+1}-s_i-1$ spaces to be filled with any of the
$\constants{}$ constants or any of the $i$ already-introduced variables.

Let us order the elements of $\predicates{}$, and let $a_i$ be the arity of the
$i$-th predicate. The number of programs is then:
\[
  \sum_{\substack{ \sum_{i=1}^{|\predicates{}|} h_i = n,\\
      |\predicates{}| \le n \le \maxNumClauses,\\
      h_i \ge 1 \text{ for all } i}} \prod_{i=1}^{|\predicates{}|}
  \multiset{\sum_{a=0}^{\maxArity{} \times \maxNumNodes{}} C(a) P(a+a_i)}{h_i},
\]
where
\[
  \multiset{n}{k} = \binom{n+k-1}{k}
\]
counts the number of ways to select $k$ out of $n$ items with repetition (and
without ordering). Here, we sum over all possible ways to distribute
$|\predicates{}| \le n \le \maxNumClauses{}$ clauses among $|\predicates{}|$
predicates so that each predicate gets at least one clause. For each predicate,
we can then count the number of ways to select its clauses out of all possible
clauses. The number of possible clauses can be computed by considering each
possible arity $a$, and multiplying the number of `unfinished' clauses $C(a)$ by
the number of ways to fill the $a+a_i$ gaps in the body and the head of the
clause with terms.

\section{Predicate Independence}

In this section, we define a notion of predicate independence as a way to
constrain the probability distributions defined by the generated programs. We
also describe efficient algorithms for propagation and entailment checking.

\begin{definition}
  Let $\mathscr{P}$ be a probabilistic logic program. Its \emph{predicate
    dependency graph} is a directed graph $G_{\mathscr{P}} = (V, E)$ with the
  set of nodes $V$ consisting of all predicates in $\mathscr{P}$. We add an edge
  from predicate $\mathsf{P}$ to predicate $\mathsf{Q}$ if there is a clause in
  $\mathscr{P}$ with $\mathsf{Q}$ as the head and $\mathsf{P}$ mentioned in the
  body.
\end{definition}

\begin{definition}
  Let $\mathsf{P}$ be a predicate in a program $\mathscr{P}$. The
  \emph{dependencies} of $\mathsf{P}$ is the smallest set $D_{\mathsf{P}}$ such
  that:
  \begin{itemize}
  \item $\mathsf{P} \in D_{\mathsf{P}}$,
  \item for every $\mathsf{Q} \in D_{\mathsf{P}}$, the nodes with arrows to
    $\mathsf{Q}$ in $G_{\mathscr{P}}$ are all in $D_{\mathsf{P}}$.
  \end{itemize}
\end{definition}

\begin{definition}
  Two predicates $\mathsf{P}$ and $\mathsf{Q}$ are \emph{independent} if
  $D_{\mathsf{P}} \cap D_{\mathsf{Q}} = \emptyset$.
\end{definition}

\begin{figure}[t]
  \centering
  \begin{tikzpicture}
    \node[draw] (father) at (0, 0.5) {$\mathsf{father}$};
    \node[draw] (mother) at (0, -0.5) {$\mathsf{mother}$};
    \node[draw] (parent) at (2, 0) {$\mathsf{parent}$};
    \node[draw] (sibling) at (4, 0) {$\mathsf{sibling}$};
    \draw[-{Stealth[scale=1.5]}] (father) -- (parent);
    \draw[-{Stealth[scale=1.5]}] (mother) -- (parent);
    \draw[-{Stealth[scale=1.5]}] (parent) -- (sibling);
  \end{tikzpicture}
  \caption{The predicate dependency graph of the program in \cref{ex:program}}
  \label{fig:predicate_dependencies}
\end{figure}

\begin{example} \label{ex:program}
  Consider the following program:
  \begin{align*}
    \mathsf{sibling}(X, Y) &\gets \mathsf{parent}(X, Z) \land \mathsf{parent}(Y, Z),\\
    \mathsf{parent}(X, Y) &\gets \mathsf{father}(X, Y) \lor \mathsf{mother}(X, Y).
  \end{align*}
  Its predicate dependency graph is in \cref{fig:predicate_dependencies}. We can
  then list the dependencies of each predicate:
  \begin{alignat*}{3}
    D_{\mathsf{father}} &= \{ \mathsf{father} \}, \quad && D_{\mathsf{parent}} &&= \{ \mathsf{father}, \mathsf{mother}, \mathsf{parent} \}, \\
    D_{\mathsf{mother}} &= \{ \mathsf{mother} \}, \quad && D_{\mathsf{sibling}} &&= \{ \mathsf{father}, \mathsf{mother}, \mathsf{parent}, \mathsf{sibling} \}.
  \end{alignat*}
  Hence, the only pair of independent predicates in this program is
  $\mathsf{father}$ and $\mathsf{mother}$.
\end{example}

% TODO: continue writing from here
\begin{definition}[Adjacency matrix representation]
  An $|\predicates{}| \times |\predicates{}|$ adjacency matrix $\mathbf{A}$
  defined by
  \begin{align*}
    A_{i,j} = 0 \iff &\nexists k: \variable{headsOfClauses}[k].\variable{predicate} = j \text{ and } \\
    &i \in \{ a.\variable{name} \mid a \in \variable{bodiesOfClauses}[k].\variable{treeValues} \}.
  \end{align*}
\end{definition}

A dependency is an algebraic data type that is either determined (in which case
it holds only the index of the predicate) or undetermined (in which case it also
holds the indices of the source and target vertices, corresponding to the edge
responsible for making the dependency undetermined).

Propagation for independence:
\begin{itemize}
\item Two types of dependencies: determined and
  one-undetermined-edge-away-from-being-determined.
\item Look up the dependencies of both predicates. For each pair of
  matching dependencies:
  \begin{itemize}
  \item If both are determined, fail.
  \item If one is determined, the selected edge of the other must not
    exist.
  \end{itemize}
\end{itemize}

\begin{algorithm}[p]
  \SetKwFunction{getDependencies}{getDependencies}
  \SetKwFunction{isDetermined}{isDetermined}
  \SetKwFunction{fail}{fail}
  \SetKwFunction{removeValue}{removeValue}
  \SetKwData{predicate}{predicate}
  \SetKwData{source}{source}
  \SetKwData{target}{target}
  \KwData{predicates $p_1$, $p_2$; adjacency matrix $\mathbf{A}$}
  \For{$(d_1, d_2) \in \getDependencies{$p_1$} \times
    \getDependencies{$p_2$}$ s.t. $d_1.\predicate = d_2.\predicate$}{
    \If{$d_1$.\isDetermined{} {\bf and} $d_2$.\isDetermined{}}{
      \fail{}\;
    }
    \uIf{$d_1$.\isDetermined{}}{
      $\mathbf{A}[d_2.\source][d_2.\target]$.\removeValue{$1$}\;
    }
    \ElseIf{$d_2$.\isDetermined{}}{
      $\mathbf{A}[d_1.\source][d_1.\target]$.\removeValue{$1$}\;
    }
  }
  \caption{Propagation}
\end{algorithm}

\begin{algorithm}[p]
  \SetKwFunction{getDependencies}{getDependencies}
  \SetKwFunction{isDetermined}{isDetermined}
  \SetKwData{predicate}{predicate}
  \KwData{predicates $p_1$, $p_2$}
  $D \gets \{ (d_1, d_2) \in \getDependencies{$p_1$} \times
  \getDependencies{$p_2$} \mid d_1.\predicate = d_2.\predicate \}$\;
  \If{$\{ (d_1, d_2) \in D \mid d_1.\isDetermined{}, d_2.\isDetermined{} \} \ne
    \emptyset$}{
    \Return{FALSE}\;
  }
  \If{$D = \emptyset$}{
    \Return{TRUE}\;
  }
  \Return{UNDEFINED}\;
  \caption{Entailment}
\end{algorithm}

\begin{algorithm}[p]
  \SetKwData{edgeExists}{edgeExists}
  \SetKwData{predicate}{predicate}
  \SetKwData{source}{source}
  \SetKwData{target}{target}
  \SetKwFunction{isDetermined}{isDetermined}
  \SetKwFunction{getDependencies}{getDependencies}
  \SetKwProg{Fn}{Function}{:}{}
  \KwData{an $n \times n$ adjacency matrix $\mathbf{A}$}
  \Fn{\getDependencies{$p$}} {
    $D \gets \{ p \}$\;
    \Repeat{$D' = D$}{
      $D' \gets D$\;
      \For{$d \in D$}{
        \For{$i \gets 1$ \KwTo $n$}{
          $\edgeExists \gets \mathbf{A}[i][d.\predicate] = \{ 1 \}$\;
          \uIf{$\edgeExists$ {\bf and} $d$.\isDetermined{}}{
            $D' \gets D' \cup \{ i \}$\;
          }
          \uElseIf{$\edgeExists$ {\bf and not} $d$.\isDetermined{}}{
            $D' \gets D' \cup \{ (i, d.\source, d.\target) \}$\;
          }
          \ElseIf{$|\mathbf{A}[i][d.\predicate]| > 1$ {\bf and} $d$.\isDetermined{}}{
            $D' \gets D' \cup \{ (i, i, d.\predicate) \}$\;
          }
        }
      }
    }
    \Return{$D$}\;
  }
  \caption{Computing the dependencies of a predicate}
\end{algorithm}

\section{Entailment Checking for Negative/All Cycles}

\begin{enumerate}
\item Let $C$ be a set of clauses such that their bodies and predicates in their
  heads are fully determined.
\item If $C = \emptyset$, return UNDEFINED.
\item Construct an adjacency list representation of a graph where vertices
  represent predicates. Each edge is either \emph{positive} or \emph{negative}.
  There is an edge from $p$ to $q$ if $q$ appears in the body of a predicate
  with $p$ as its head. The edge is negative if, when traversing the tree to
  reach some instance of $q$, we pass through a $\neg$ node. Otherwise, it's
  positive.
\item Run a modified cycle detection algorithm that detects all cycles that have
  at least one negative edge.
\item If we found a cycle, return FALSE.
\item If $C$ encompasses all clauses, return TRUE.
\item Return UNDEFINED.
\end{enumerate}

% \section{Conditional Independence}

% Finish the propagation algorithm for conditional independence. The
%  propagation algorithm for independence is extended with masks that are either
%  potential or definite. Masking happens in two stages: first, we mask
%  expressions within formulas, and then predicates. Masking algorithm uses an
%  algorithm for perfect bipartite matching.

% Both determined $\implies$ fail(). Both determined but at least is one masked by
% a (probable/determined) mask $\implies$ nothing. One determined $\implies$ the
% other one cannot exist.

% \begin{algorithm}
%   \SetKwProg{Fn}{Function}{:}{}
%   \SetKwFunction{potentialRoots}{potentialRoots}
%   \SetKwFunction{getTreeValues}{getTreeValues}
%   \SetKwFunction{getTreeStructureDomainValues}{getTreeStructureDomainValues}
%   \SetKwData{clause}{clause}
%   \KwData{connective $c$, a set of predicates $P$}
%   \Fn{\potentialRoots{\clause, $i$}} {
%     $R \gets \emptyset$\;
%     $V \gets \clause.\getTreeValues{$i$}$\;
%     \For{$v \in V$}{
%       \uIf{$v = c$}{
%         $R \gets R \cup \{ (i, |V| = 1) \}$\;
%       }
%       \ElseIf{$v \in P$}{
%         $R' \gets \clause.\getTreeStructureDomainValues{$i$}$\;
%         $R \gets R \cup \{ (r, |R'| = 1) \mid r \in R' \}$\;
%       }
%     }
%     \Return{$R$}\;
%   }
%   \caption{Potential root nodes of the required expression, assuming that the
%     node at index $i$ is part of the expression}
% \end{algorithm}

\section{Conclusion \& Future Work}

\begin{itemize}
\item A constraint for logical equivalence. An algorithm to reduce each tree to
  some kind of normal form. Not doing this on purpose. Leaving for further work.
\item Perhaps negative cycle detection could use the same graph as the
  independence propagator? If we extend each domain to {-1, 0, 1}, but that
  might make propagation weaker or slower.
\item Could investigate how uniform the generated distribution of programs is.
  Distributions of individual parameters will often favour larger values
  because, e.g., there are more 5-tuples than 4-tuples.
\item Inference options to explore. Logspace vs normal space. Symbolic vs
  non-symbolic. Propagate evidence (might be irrelevant)? Propagate weights?
  Supported knowledge compilation techniques: sdd, sddx, bdd, nnf, ddnnf, kbest,
  fsdd, fbdd.
\item Mention the random heuristic. Mention that restarting gives better
  randomness, but duplicates become possible. Restarting after each run is
  expensive. Periodic restarts could be an option.
\end{itemize}

\section*{Acknowledgments}

% The author would like to thank Vaishak Belle for his comments.
This work was supported by the EPSRC Centre for Doctoral Training in Robotics
and Autonomous Systems, funded by the UK Engineering and Physical Sciences
Research Council (grant EP/S023208/1).

\bibliographystyle{splncs04}
\bibliography{paper}

\end{document}